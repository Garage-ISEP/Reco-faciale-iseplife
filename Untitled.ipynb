{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb4aae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\lilia\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc67d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6122e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.22621.2283]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>where python\n",
      "C:\\Users\\lilia\\anaconda3\\python.exe\n",
      "C:\\Program Files\\Python311\\python.exe\n",
      "C:\\Users\\lilia\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e0cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.22621.2283]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>python --version\n",
      "Python 3.10.9\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3de7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.22621.2283]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>pip install cmake\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.27.7-py2.py3-none-win_amd64.whl (34.6 MB)\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.27.7\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea566a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.22621.2283]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>pip install https://github.com/jloh02/dlib/releases/download/v19.22/dlib-19.22.99-cp310-cp310-win_amd64.whl\n",
      "Collecting dlib==19.22.99\n",
      "  Downloading https://github.com/jloh02/dlib/releases/download/v19.22/dlib-19.22.99-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.22.99\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install https://github.com/jloh02/dlib/releases/download/v19.22/dlib-19.22.99-cp310-cp310-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e4ce906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.22621.2283]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>pip install face-recognition\n",
      "Collecting face-recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\lilia\\anaconda3\\lib\\site-packages (from face-recognition) (8.0.4)\n",
      "Collecting face-recognition-models>=0.3.0\n",
      "  Using cached face_recognition_models-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Pillow in c:\\users\\lilia\\anaconda3\\lib\\site-packages (from face-recognition) (9.4.0)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\lilia\\anaconda3\\lib\\site-packages (from face-recognition) (19.22.99)\n",
      "Requirement already satisfied: numpy in c:\\users\\lilia\\anaconda3\\lib\\site-packages (from face-recognition) (1.23.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lilia\\anaconda3\\lib\\site-packages (from Click>=6.0->face-recognition) (0.4.6)\n",
      "Installing collected packages: face-recognition-models, face-recognition\n",
      "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
      "\n",
      "(base) C:\\Users\\lilia\\OneDrive\\Bureau\\ML\\iseplife>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f802aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben is inJournée du samedi-217788.jpg\n",
      "ben is inJournée du samedi-218189.jpg\n",
      "ben is inJournée du vendredi-215861.jpg\n",
      "ben is inSoirée du samedi-221557.jpg\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "# Charger les images et les encodages des visages (base de données)\n",
    "\n",
    "imageBen = face_recognition.load_image_file(\"photos_sujet/test_ben.jpg\")\n",
    "ben = face_recognition.face_encodings(imageBen)[0]\n",
    "\n",
    "\n",
    "\n",
    "directory = 'photos_test'\n",
    "for filename in os.listdir(directory):\n",
    "    image = face_recognition.load_image_file(directory+\"/\"+ filename)\n",
    "    encoding=[]\n",
    "    for i in range(len(face_recognition.face_encodings(image))):\n",
    "        encoding.append(face_recognition.face_encodings(image)[i])\n",
    "    for i in range(len(encoding)):\n",
    "        result = face_recognition.compare_faces([encoding[i]], ben)\n",
    "\n",
    "        if result[0]:\n",
    "            print(\"ben is in\" + str(filename))\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Comparer les encodages pour déterminer si les visages correspondent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad5d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def string_to_np_array(input_string):\n",
    "    # Supprimer les crochets carrés et les espaces autour du string\n",
    "    input_string = input_string.strip('[]').replace('\\n', '').split()\n",
    "\n",
    "    # Convertir les éléments en float et créer un tableau NumPy\n",
    "    np_array = np.array([float(x) for x in input_string])\n",
    "\n",
    "    return np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f30e464",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      5\u001b[0m imageBen \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mload_image_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphotos_sujet/test_ben.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m ben \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimageBen\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_encoded/face.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py:213\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mface_encodings\u001b[39m(face_image, known_face_locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_jitters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    Given an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    :return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     raw_landmarks \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_face_landmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py:156\u001b[0m, in \u001b[0;36m_raw_face_landmarks\u001b[1;34m(face_image, face_locations, model)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raw_face_landmarks\u001b[39m(face_image, face_locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m face_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m         face_locations \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         face_locations \u001b[38;5;241m=\u001b[39m [_css_to_rect(face_location) \u001b[38;5;28;01mfor\u001b[39;00m face_location \u001b[38;5;129;01min\u001b[39;00m face_locations]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#encode\n",
    "import face_recognition\n",
    "import os\n",
    "import json\n",
    "imageBen = face_recognition.load_image_file(\"photos_sujet/test_ben.jpg\")\n",
    "ben = face_recognition.face_encodings(imageBen)[0]\n",
    "\n",
    "with open('face_encoded/face.json', 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    data['ben'] = str(ben) # <--- add `id` value.\n",
    "    f.seek(0)        # <--- should reset file position to the beginning.\n",
    "    json.dump(data, f, indent=4)\n",
    "    f.truncate() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1811bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face_in_photos(face_name):\n",
    "    import numpy as np\n",
    "    directory = 'photos_test'\n",
    "    \n",
    "    with open('face_encoded/face.json', 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        ben_str = data[face_name]\n",
    "        ben = string_to_np_array(ben_str)\n",
    "\n",
    "        f.close()\n",
    "         \n",
    "\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        image = face_recognition.load_image_file(directory+\"/\"+ filename)\n",
    "        encoding=[]\n",
    "        for i in range(len(face_recognition.face_encodings(image))):\n",
    "            encoding.append(face_recognition.face_encodings(image)[i])\n",
    "        for i in range(len(encoding)):\n",
    "            result = face_recognition.compare_faces([encoding[i]], ben)\n",
    "\n",
    "            if result[0]:\n",
    "                print(\"ben is in\" + str(filename))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a95be3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben is inJournée du samedi-217788.jpg\n",
      "ben is inJournée du samedi-218189.jpg\n",
      "ben is inJournée du vendredi-215861.jpg\n",
      "ben is inSoirée du samedi-221557.jpg\n"
     ]
    }
   ],
   "source": [
    "find_face_in_photos(\"ben\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a7d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
